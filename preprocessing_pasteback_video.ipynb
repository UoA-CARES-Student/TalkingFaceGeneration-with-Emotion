{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WOXc8JlA4zi"
      },
      "source": [
        "# **Connect to google drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GSPJSTl_xiD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8W9HRyVA8kZ"
      },
      "source": [
        "folder location where your images are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV3fHxoaBqmq"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/p4p/pasteback_operation/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKv6VSPpBLOI"
      },
      "source": [
        "any folder location where you want to download \"shape_predictor_68_face_landmarks\" file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMyg4bEFGle3"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/p4p/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw5VwmM4BY-1"
      },
      "outputs": [],
      "source": [
        "!wget   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # DOWNLOAD LINK\n",
        "\n",
        "!bunzip2 /content/gdrive/MyDrive/p4p/shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mif8pDhsHIR0"
      },
      "outputs": [],
      "source": [
        "datFile =  \"/content/gdrive/MyDrive/p4p/shape_predictor_68_face_landmarks.dat\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO2OTxLBUgyJ"
      },
      "source": [
        "# **Paste back operation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SAIVa2fmc6a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "\n",
        "# Image paths\n",
        "img1_path = '/content/gdrive/MyDrive/p4p/pasteback_operation/scarlette.png'         # original image path\n",
        "img2_path = '/content/gdrive/MyDrive/p4p/pasteback_operation/scarlette_disgust.png'       # cropped image path\n",
        "output1_path = '/content/gdrive/MyDrive/p4p/pasteback_operation/scarlette_done.jpg'         # output image path\n",
        "\n",
        "# Load images\n",
        "img1 = cv2.imread(img1_path)\n",
        "img2 = cv2.imread(img2_path)\n",
        "\n",
        "# Initialize dlib's face detector and predictor\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(datFile)\n",
        "\n",
        "# Get the landmarks\n",
        "def get_landmarks(image):\n",
        "    rects = detector(image, 1)\n",
        "    if len(rects) != 1:\n",
        "        return None\n",
        "    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n",
        "\n",
        "# Align the image based on the eyes position\n",
        "def align_face(image, landmarks):\n",
        "    left_eye = np.mean(landmarks[36:42], axis=0).tolist()[0]\n",
        "    right_eye = np.mean(landmarks[42:48], axis=0).tolist()[0]\n",
        "\n",
        "    dy = right_eye[1] - left_eye[1]\n",
        "    dx = right_eye[0] - left_eye[0]\n",
        "    angle = np.degrees(np.arctan2(dy, dx))\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
        "    aligned = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
        "\n",
        "    return aligned\n",
        "\n",
        "# Get landmarks for img1 and aligned face for img2\n",
        "landmarks1 = get_landmarks(img1)\n",
        "landmarks2 = get_landmarks(img2)\n",
        "\n",
        "if landmarks1 is None or landmarks2 is None:\n",
        "    print(\"Couldn't detect face landmarks.\")\n",
        "    exit()\n",
        "\n",
        "aligned_img2 = align_face(img2, landmarks2)\n",
        "\n",
        "# Extract faces from the images\n",
        "x1, y1, w1, h1 = cv2.boundingRect(np.array(landmarks1))\n",
        "x2, y2, w2, h2 = cv2.boundingRect(np.array(landmarks2))\n",
        "\n",
        "face1 = img1[y1:y1+h1, x1:x1+w1]\n",
        "face2 = aligned_img2[y2:y2+h2, x2:x2+w2]\n",
        "\n",
        "# Resize and mask generation\n",
        "resize_pct = 0.50\n",
        "face2 = cv2.resize(face2, (int(face2.shape[1] * resize_pct), int(face2.shape[0] * resize_pct)))\n",
        "\n",
        "def create_soft_mask(face):\n",
        "    mask = np.ones_like(face) * 255\n",
        "    h, w, _ = face.shape\n",
        "    mask[:15, :, :] = 0\n",
        "    mask[h-15:, :, :] = 0\n",
        "    mask[:, :15, :] = 0\n",
        "    mask[:, w-15:, :] = 0\n",
        "    mask = cv2.GaussianBlur(mask, (51, 51), 0)\n",
        "    return mask\n",
        "\n",
        "mask1 = create_soft_mask(face1)\n",
        "face2_resized = cv2.resize(face2, (w1, h1))\n",
        "mask2_resized = cv2.resize(create_soft_mask(face2), (w1, h1))\n",
        "center1 = (x1 + w1 // 2, y1 + h1 // 2)\n",
        "\n",
        "# Seamless clone\n",
        "img1_face_swapped = cv2.seamlessClone(face2_resized, img1, mask2_resized, center1, cv2.NORMAL_CLONE)\n",
        "\n",
        "# Save the results\n",
        "cv2.imwrite(output1_path, img1_face_swapped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5QGHC84UdqN"
      },
      "source": [
        "# **Image to Video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ahMI9ynUDdm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Path to the image and desired output video\n",
        "image_path = '/content/gdrive/MyDrive/p4p/pasteback_operation/scarlette_done.jpg'       # image path\n",
        "output_path = '/content/gdrive/MyDrive/p4p/pasteback_operation/scarlette.avi'           # output video path\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread(image_path)\n",
        "if img is None:\n",
        "    print(f\"Failed to load image at {image_path}\")\n",
        "    exit()\n",
        "\n",
        "# Extract image dimensions\n",
        "height, width, layers = img.shape\n",
        "size = (width, height)\n",
        "\n",
        "# Define video writer\n",
        "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "\n",
        "# Write the image frame 60 times for 4 seconds of video at 15 fps\n",
        "for _ in range(60):\n",
        "    out.write(img)\n",
        "\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
